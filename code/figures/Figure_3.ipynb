{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform generalized linear mixed-model (logistic) on probability of being correct, word by word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import FloatVector, FactorVector, globalenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call R\n",
    "lme4 = importr('lme4')\n",
    "base = importr('base')\n",
    "stats = importr('stats')\n",
    "lmerTest = importr('lmerTest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous, current = os.path.split(os.getcwd())\n",
    "dname = previous[0:-5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files\n",
    "fname_words = dname+\"\\\\data\\\\all_subjects_words_GPT2_big.pkl\"\n",
    "fname_sentences = dname+\"\\\\data\\\\all_subjects_sentences_GPT2_big.pkl\"\n",
    "# get words and sentences data\n",
    "df_words = pickle.load(open(fname_words, 'rb'))\n",
    "df_sentences = pickle.load(open(fname_sentences, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for R and fit GLMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit two different GLMMs to words and sentences data\n",
    "\n",
    "glmms = []\n",
    "for i, (df, weight) in enumerate(zip((df_words, df_sentences), (1, 7))):\n",
    "    \n",
    "    # Declare variables in R environment\n",
    "    globalenv[\"score\"] = FloatVector(df['score'].ravel())                               # actual comprehension score\n",
    "    globalenv[\"vitesse\"] = FactorVector(np.array(df['vitesse'], dtype=np.str).ravel())  # presentation speed\n",
    "    globalenv[\"suj\"] = FactorVector(np.array(df['suj'], dtype=np.str).ravel())          # subject id\n",
    "    globalenv[\"syll_rate\"] = FloatVector(df['syll_rate'].ravel())                       # syllabic rate\n",
    "    globalenv[\"phon_rate\"] = FloatVector(df['phon_rate'].ravel())                       # phonemic rate\n",
    "    globalenv[\"syir_rate\"] = FloatVector(df['syir_rate'].ravel())                       # syllabic information rate\n",
    "    globalenv[\"phir_rate\"] = FloatVector(df['phir_rate'].ravel())                       # phonemic information rate\n",
    "    globalenv[\"stat_surp\"] = FloatVector(df['stat_surp'].ravel())                       # static lexical surprise rate\n",
    "    globalenv[\"ctxt_surp_BERT\"] = FloatVector(df['ctxt_surp_BERT'].ravel())             # contextual lexical surprise\n",
    "    globalenv[\"ctxt_surp_GPT2_big\"] = FloatVector(df['ctxt_surp_GPT2_big'].ravel())     # contextual lexical surprise\n",
    "    globalenv[\"peak_env\"] = FloatVector(df['peak_env'].ravel())                         # acoustic modulation rate\n",
    "    globalenv[\"weights\"] = FloatVector(np.ones(df['score'].shape).ravel() * weight)     # weight argument for the GLMM\n",
    "    \n",
    "    #         \" + scale(ctxt_surp_GPT2_big, center = TRUE, scale = TRUE)\" + \\\n",
    "    # Fit GLMM for words data\n",
    "    if i == 0:\n",
    "        formula = \"score ~ \" + \\\n",
    "        \"   scale(peak_env,  center = TRUE, scale = TRUE)\" + \\\n",
    "        \" + scale(phon_rate, center = TRUE, scale = TRUE)\" + \\\n",
    "        \" + scale(syll_rate, center = TRUE, scale = TRUE)\" + \\\n",
    "        \" + scale(phir_rate, center = TRUE, scale = TRUE)\" + \\\n",
    "        \" + scale(stat_surp, center = TRUE, scale = TRUE)\" + \\\n",
    "        \" + (1|vitesse) + (1|suj)\"\n",
    "        \n",
    "    # Fit GLMM for sentences data\n",
    "    if i == 1:\n",
    "        formula = \"score ~ \" + \\\n",
    "        \"   scale(peak_env,  center = TRUE, scale = TRUE)\" + \\\n",
    "        \" + scale(phon_rate, center = TRUE, scale = TRUE)\" + \\\n",
    "        \" + scale(syll_rate, center = TRUE, scale = TRUE)\" + \\\n",
    "        \" + scale(phir_rate, center = TRUE, scale = TRUE)\" + \\\n",
    "        \" + scale(syir_rate, center = TRUE, scale = TRUE)\" + \\\n",
    "        \" + scale(stat_surp, center = TRUE, scale = TRUE)\" + \\\n",
    "        \" + scale(ctxt_surp_BERT, center = TRUE, scale = TRUE)\" + \\\n",
    "        \" + (1|vitesse) + (1|suj)\"\n",
    "    print(formula)\n",
    "    m = lme4.glmer(formula, family='binomial', weights=globalenv[\"weights\"])\n",
    "    glmms.append(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print GLMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base.summary(glmms[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentences\n",
    "print(base.summary(glmms[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Figure 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_variables = 8\n",
    "variable_names = [\n",
    "    r'Intercept',\n",
    "    r'Acoustic modulation rate ($s^{-1}$)',\n",
    "    r'Phonemic rate ($s^{-1}$)',\n",
    "    r'Syllabic rate ($s^{-1}$)',\n",
    "    r'Phonemic information ($bit.s^{-1}$)',\n",
    "    r'Syllabic information ($bit.s^{-1}$)', \n",
    "    r'Static lexical surprise ($bit.s^{-1}$)',\n",
    "    r'Contextual lexical surprise ($bit.s^{-1}$)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['grey','#e41a1c', '#ff7f00','#efca08',  '#4daf4a', '#377eb8', 'darkorchid']\n",
    "titles = [r'$\\it{Experiment\\ 1}$' + \"\\n\" + r'$\\bf{Words}$', \n",
    "          r'$\\it{Experiment\\ 2}$' + \"\\n\" + r'$\\bf{Sentences}$']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# I don't know why but it needs to be run twice to get the final design :/\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(7.09, 2), facecolor='w', dpi=300)\n",
    "plt.rcParams[\"font.size\"] = \"7\"\n",
    "\n",
    "all_coef = []\n",
    "all_se = []\n",
    "for i, (ax, title, m) in enumerate(zip(axs, titles, glmms)):\n",
    "    \n",
    "    # Get model coefficients\n",
    "    coefs = np.array(base.summary(m)[9])[:, 0]\n",
    "    se = np.array(base.summary(m)[9])[:, 1]\n",
    "    pvals = np.array(base.summary(m)[9])[:, 3]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Add a column to glmms[0] because ctxt_surp is missing \n",
    "    if i == 0:\n",
    "        coefs = np.r_[ coefs[0],  coefs[1:5], [np.nan], coefs[5], [np.nan] ]\n",
    "        se    = np.r_[    se[0],    se[1:5], [np.nan],    se[5], [np.nan] ]\n",
    "        pvals = np.r_[ pvals[0], pvals[1:5], [np.nan], pvals[5], [np.nan] ]\n",
    "    \n",
    "    \n",
    "    # Plot\n",
    "    for j, color in zip(np.arange(1, n_variables), colors): # Remove intercept \n",
    "        \n",
    "        # Plot points + se\n",
    "        markerfacecolor = color\n",
    "        ax.errorbar(coefs[j], y=j, xerr=se[j], marker='o', \n",
    "                    elinewidth=3, linewidth=0.5, color=color, \n",
    "                    markerfacecolor=markerfacecolor, markeredgecolor='k', ms=8)\n",
    "        all_coef.append(coefs[j])\n",
    "        all_se.append(se[j])\n",
    "        # Plot * of p-values\n",
    "        txt = '' if pvals[j] > 0.05 else ('*' if pvals[j] > 0.01 else ('**' if pvals[j] > 0.001 else '***'))\n",
    "        ax.annotate(txt, (coefs[j], j+0.65), va='center', ha='center', color=color)\n",
    "\n",
    "    # Aesthetics\n",
    "    ax.axvline(0, color='k', linestyle='--', alpha=0.5)\n",
    "    ax.set_ylim(n_variables, 0)\n",
    "    ax.set_xlim(-1.2, 0.45)\n",
    "    ax.set_xlabel('Log-odds / $\\Delta_{\\sigma^2}$')\n",
    "    ax.set_title(title, fontweight='bold', pad=15)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.set_yticks(np.arange(1, n_variables))\n",
    "    if i == 0:\n",
    "        ax.set_yticklabels(variable_names[1:])\n",
    "    else:\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "    # Arrows\n",
    "    l = 0.25\n",
    "    x = 0\n",
    "    y = 0.4\n",
    "    hw = 0.4\n",
    "    hl = 0.1\n",
    "    offset = 0.1\n",
    "    ax.arrow(x + offset, y, l, 0, head_width=hw, shape='right', head_length=hl, \n",
    "             color='k', linestyle='--', alpha=0.5)\n",
    "    ax.arrow(x - offset, y, -l, 0, head_width=hw, shape='left', head_length=hl, \n",
    "             color='k', linestyle='--', alpha=0.5)\n",
    "    ax.annotate('improves', (x + l, y - 0.4), va='center', ha='center', alpha=0.5)\n",
    "    ax.annotate('impairs', (x - l, y - 0.4), va='center', ha='center', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig.savefig(\"/home/jeremy/chan_cap/figures/Figure_3.png\", dpi=300, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
